{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af912719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np \n",
    "import onnxruntime as ort\n",
    "import onnx\n",
    "import datasets\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "343ce006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "def t_cropflip_augment_apply(examples):\n",
    "    examples['img'] = [t_cropflip_augment(image) for image in examples['img']]\n",
    "    return examples\n",
    "    \n",
    "def t_normalize_apply(examples):\n",
    "    examples['img'] = [t_normalize(image) for image in examples['img']]\n",
    "    return examples\n",
    "\n",
    "# Also make them float\n",
    "t_cropflip_augment = transforms.Compose([\n",
    "    # take_img,\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "t_normalize = transforms.Compose([\n",
    "    # take_img,\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0931dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.load_dataset(\"uoft-cs/cifar10\", split=\"train\")\n",
    "test_set = datasets.load_dataset(\"uoft-cs/cifar10\", split=\"test\")\n",
    "\n",
    "train_set.set_transform(t_cropflip_augment_apply)\n",
    "test_set.set_transform(t_normalize_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6d8d25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': tensor([[[-2.4291, -2.4291, -2.4291,  ...,  1.0408,  1.0408,  1.0214],\n",
       "          [-2.4291, -2.4291, -2.4291,  ...,  1.0796,  1.0602,  1.0602],\n",
       "          [-2.4291, -2.4291, -2.4291,  ...,  1.0214,  1.0214,  1.0214],\n",
       "          ...,\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -0.1223, -0.1223, -0.1804],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -0.2192, -0.1998, -0.2386],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -0.4906, -0.4712, -0.5100]],\n",
       " \n",
       "         [[-2.4183, -2.4183, -2.4183,  ...,  1.0628,  1.0628,  1.0431],\n",
       "          [-2.4183, -2.4183, -2.4183,  ...,  1.1021,  1.1021,  1.0824],\n",
       "          [-2.4183, -2.4183, -2.4183,  ...,  1.0431,  1.0431,  1.0431],\n",
       "          ...,\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -0.1959, -0.2156, -0.2549],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -0.3729, -0.3729, -0.3926],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -0.5696, -0.5892, -0.5696]],\n",
       " \n",
       "         [[-2.2214, -2.2214, -2.2214,  ...,  1.4661,  1.4856,  1.4661],\n",
       "          [-2.2214, -2.2214, -2.2214,  ...,  1.5051,  1.5246,  1.5051],\n",
       "          [-2.2214, -2.2214, -2.2214,  ...,  1.4465,  1.4661,  1.4661],\n",
       "          ...,\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -0.0362, -0.0753, -0.0753],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -0.2118, -0.2118, -0.2313],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -0.5045, -0.5045, -0.5045]]]),\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "26e5996e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0129, -0.0098,  0.0177,  0.0182,  0.0055, -0.0097,  0.0260, -0.0277,\n",
       "          0.0244,  0.0026]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_set[0]['img'].to(device).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6b4c318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Loss:  tensor(300.7662, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.3930, device='cuda:0')\n",
      "Epoch:  1  Loss:  tensor(250.1091, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.4981, device='cuda:0')\n",
      "Epoch:  2  Loss:  tensor(226.3119, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.4942, device='cuda:0')\n",
      "Epoch:  3  Loss:  tensor(207.7799, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.5307, device='cuda:0')\n",
      "Epoch:  4  Loss:  tensor(194.2081, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.5351, device='cuda:0')\n",
      "Epoch:  5  Loss:  tensor(178.2174, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.5880, device='cuda:0')\n",
      "Epoch:  6  Loss:  tensor(165.9576, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.6342, device='cuda:0')\n",
      "Epoch:  7  Loss:  tensor(152.4278, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.6535, device='cuda:0')\n",
      "Epoch:  8  Loss:  tensor(138.1372, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.6460, device='cuda:0')\n",
      "Epoch:  9  Loss:  tensor(128.0838, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.7107, device='cuda:0')\n",
      "Epoch:  10  Loss:  tensor(111.1559, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.7139, device='cuda:0')\n",
      "Epoch:  11  Loss:  tensor(106.5111, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.7532, device='cuda:0')\n",
      "Epoch:  12  Loss:  tensor(91.4036, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.7621, device='cuda:0')\n",
      "Epoch:  13  Loss:  tensor(86.2393, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.7693, device='cuda:0')\n",
      "Epoch:  14  Loss:  tensor(72.5013, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.7421, device='cuda:0')\n",
      "Epoch:  15  Loss:  tensor(70.8312, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.7946, device='cuda:0')\n",
      "Epoch:  16  Loss:  tensor(62.3740, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.8202, device='cuda:0')\n",
      "Epoch:  17  Loss:  tensor(53.3513, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.8510, device='cuda:0')\n",
      "Epoch:  18  Loss:  tensor(49.6672, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.8617, device='cuda:0')\n",
      "Epoch:  19  Loss:  tensor(48.6006, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.8500, device='cuda:0')\n",
      "Epoch:  20  Loss:  tensor(42.7803, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.8919, device='cuda:0')\n",
      "Epoch:  21  Loss:  tensor(34.8919, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.8787, device='cuda:0')\n",
      "Epoch:  22  Loss:  tensor(34.9189, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.8835, device='cuda:0')\n",
      "Epoch:  23  Loss:  tensor(37.4716, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.8798, device='cuda:0')\n",
      "Epoch:  24  Loss:  tensor(28.9293, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.8929, device='cuda:0')\n",
      "Epoch:  25  Loss:  tensor(29.5538, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9339, device='cuda:0')\n",
      "Epoch:  26  Loss:  tensor(28.7597, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9178, device='cuda:0')\n",
      "Epoch:  27  Loss:  tensor(27.1525, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9064, device='cuda:0')\n",
      "Epoch:  28  Loss:  tensor(25.6621, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9267, device='cuda:0')\n",
      "Epoch:  29  Loss:  tensor(21.9433, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9332, device='cuda:0')\n",
      "Epoch:  30  Loss:  tensor(20.5407, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9299, device='cuda:0')\n",
      "Epoch:  31  Loss:  tensor(22.0274, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9440, device='cuda:0')\n",
      "Epoch:  32  Loss:  tensor(23.1338, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9278, device='cuda:0')\n",
      "Epoch:  33  Loss:  tensor(23.3214, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9418, device='cuda:0')\n",
      "Epoch:  34  Loss:  tensor(19.4030, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9441, device='cuda:0')\n",
      "Epoch:  35  Loss:  tensor(16.6899, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9443, device='cuda:0')\n",
      "Epoch:  36  Loss:  tensor(18.8241, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9126, device='cuda:0')\n",
      "Epoch:  37  Loss:  tensor(22.4570, device='cuda:0', grad_fn=<AddBackward0>)  Accuracy:  tensor(0.9399, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 70\u001b[0m\n\u001b[1;32m     58\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     59\u001b[0m     train_set,\n\u001b[1;32m     60\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     61\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     64\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     65\u001b[0m     test_set,\n\u001b[1;32m     66\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     67\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     68\u001b[0m )\n\u001b[0;32m---> 70\u001b[0m \u001b[43msup_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_set\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[79], line 11\u001b[0m, in \u001b[0;36msup_train\u001b[0;34m(model, train_loader, test_loader, test_set, optimizer, criterion, learning_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indic \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 11\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mindic\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     labels \u001b[38;5;241m=\u001b[39m indic[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models import mbv2\n",
    "\n",
    "def sup_train(model, train_loader, test_loader, test_set, optimizer, criterion, learning_epochs):\n",
    "    for epoch in range(learning_epochs):\n",
    "        model.train()\n",
    "        epochscore = 0\n",
    "        runloss = 0\n",
    "        for indic in test_loader:\n",
    "            model.train()\n",
    "            inputs = indic[\"img\"].to(device)\n",
    "            labels = indic[\"label\"].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss\n",
    "            \n",
    "            _, preds = torch.max(outputs,1)\n",
    "            epochscore += torch.sum(preds == labels.data)\n",
    "\n",
    "            model.eval()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            _,accuracy = test(model, test_loader, criterion, test_set)\n",
    "            print(\"Epoch: \", epoch, \" Loss: \", runloss, \" Accuracy: \", accuracy)\n",
    "\n",
    "def test(model, test_loader, criterion, test_set):       \n",
    "    ''' Tests the accuracy of the dp model on testset ''' \n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    total_correct=0\n",
    "    for indic in test_loader:\n",
    "        inputs = indic[\"img\"].to(device)\n",
    "        labels = indic[\"label\"].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss += criterion(outputs, labels).item()\n",
    "        _, preds = torch.max(outputs,1)\n",
    "        total_correct += torch.sum(preds == labels.data)\n",
    "    accuracy = total_correct/len(test_set)\n",
    "    return loss,accuracy\n",
    "\n",
    "\n",
    "\n",
    "learning_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "model = mbv2.MobileNetV2(\n",
    "    num_classes=10,\n",
    "    width_mult=1.0\n",
    ").to(device)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "sup_train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    learning_epochs=learning_epochs,\n",
    "    test_loader=test_loader,\n",
    "    test_set = test_set\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2555251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28.13067110395059, tensor(0.9410, device='cuda:0'))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_loader, torch.nn.CrossEntropyLoss(), test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4a27a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"saved_models/mbv2_cifar10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "224b1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = test_set[0]['img'].unsqueeze(0).to(device)\n",
    "torch.onnx.export(model, example_input, \"onnx_models/mbv2_cifar10.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralcompressor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
